{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"D:/Kuliah/NonAkademik/FindIT 2024/dataset/train_features.csv\")\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merubah data tahun kelahiran menjadi umur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df2=pd.read_csv('D:/Kuliah/NonAkademik/FindIT 2024/dataset/train_labels.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df=pd.concat([df1,df2],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['umur'] = 2015 - df['tahun_kelahiran']\n",
    "df = df.drop(\"tahun_kelahiran\", axis=1)\n",
    "# print(df[\"umur\"].value_counts())\n",
    "\n",
    "Q1 = df['umur'].quantile(0.25)\n",
    "Q3 = df['umur'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 2 * IQR\n",
    "upper_bound = Q3 + 2 * IQR\n",
    "\n",
    "outliers = df[(df['umur'] < lower_bound) | (df['umur'] > upper_bound)]\n",
    "\n",
    "df.loc[(df['umur'] < lower_bound) | (df['umur'] > upper_bound), 'umur'] = np.nan\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perbaikan Data Pendidikan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df['pendidikan'] = df['pendidikan'].replace(5, np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perbaikan Data Pernikahan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df['status_pernikahan'] = df['status_pernikahan'].replace(5, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merubah Data tanggal menjadi anggota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "df['tanggal_menjadi_anggota'] = pd.to_datetime(df['tanggal_menjadi_anggota'], errors='coerce')\n",
    "\n",
    "current_date = pd.to_datetime('2014-07-01')\n",
    "\n",
    "df['keanggotaan'] = ((current_date.year - df['tanggal_menjadi_anggota'].dt.year) * 12 +\n",
    "                            (current_date.month - df['tanggal_menjadi_anggota'].dt.month))\n",
    "\n",
    "df = df.drop(\"tanggal_menjadi_anggota\", axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df['keanggotaan'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Anak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# df[\"jumlah_anak\"] = df['jumlah_anak_balita'] + df['jumlah_anak_remaja']\n",
    "# df['jumlah_anak'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pembuangan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# drop = ['jumlah_anak_balita', 'jumlah_anak_remaja']\n",
    "# df = df.drop(drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre pro tahap 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping Data Pendidikan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df['pendidikan'] = df['pendidikan'].replace({'Magister': 'Pasca_Sarjana', 'Doktor': 'Pasca_Sarjana'})\n",
    "# df['pendidikan'] = df['pendidikan'].replace({'SMP': 'Sekolah_Menengah', 'SMA': 'Sekolah_Menengah'})\n",
    "\n",
    "# # 0.75\n",
    "# education_order = {\n",
    "#     'SMP': 0,\n",
    "#     'SMA': 1,        \n",
    "#     'Sarjana': 2,   \n",
    "#     'Magister': 3,\n",
    "#     'Doktor': 4\n",
    "# }\n",
    "\n",
    "# # 0.7612\n",
    "# education_order = {\n",
    "#     'Sekolah_Menengah': 0,       \n",
    "#     'Sarjana': 1,   \n",
    "#     'Magister': 2,\n",
    "#     'Doktor': 3\n",
    "# }\n",
    "\n",
    "# 0.7621 (Terbaik)\n",
    "education_order = {\n",
    "    'SMP': 0,\n",
    "    'SMA': 1,        \n",
    "    'Sarjana': 2,   \n",
    "    'Pasca_Sarjana': 3\n",
    "}\n",
    "\n",
    "# # 0.7590\n",
    "# education_order = {\n",
    "#     'Sekolah_Menengah': 0,     \n",
    "#     'Sarjana': 1,   \n",
    "#     'Pasca_Sarjana': 2\n",
    "# }\n",
    "\n",
    "df['pendidikan'] = df['pendidikan'].map(education_order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping Status Pernikahan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# df['status_pernikahan'] = df['status_pernikahan'].replace({'Sendiri': 'Single', 'Cerai':'Single', 'Cerai Mati': 'Single'})\n",
    "# df['status_pernikahan'] = df['status_pernikahan'].replace({'Cerai':'Pisah', 'Cerai Mati': 'Pisah'})\n",
    "\n",
    "# 0.7621\n",
    "status_order = {\n",
    "    'Sendiri': 0,\n",
    "    'Rencana Menikah': 1,  # Planning to marry\n",
    "    'Menikah': 2,\n",
    "    'Cerai': 3,\n",
    "    'Cerai Mati': 4\n",
    "}\n",
    "\n",
    "# # 0.7519\n",
    "# status_order = {\n",
    "#     'Sendiri': 0,\n",
    "#     'Rencana Menikah': 1,  # Planning to marry\n",
    "#     'Menikah': 2,\n",
    "#     'Pisah': 3\n",
    "# }\n",
    "\n",
    "# # 0.7432\n",
    "# status_order = {\n",
    "#     'Single': 0,\n",
    "#     'Rencana Menikah': 1,  # Planning to marry\n",
    "#     'Menikah': 2\n",
    "# }\n",
    "\n",
    "\n",
    "df['status_pernikahan'] = df['status_pernikahan'].map(status_order)\n",
    "\n",
    "# print(df['status_pernikahan'].value_counts())\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(df['keluhan'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputasi Kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def impute_categorical_data_with_lightgbm(df, column_to_impute, categorical_columns):\n",
    "    df_with_missing = df[df[column_to_impute].isna()].copy()\n",
    "    df_without_missing = df[~df[column_to_impute].isna()].copy()\n",
    "\n",
    "    X = df_without_missing.drop(columns=[column_to_impute, 'jumlah_promosi'])\n",
    "    y = df_without_missing[column_to_impute]\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        if col != column_to_impute and col in X.columns:\n",
    "            X[col] = X[col].astype('category')\n",
    "        if col in df_with_missing.columns:\n",
    "            df_with_missing[col] = df_with_missing[col].astype('category')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=31,\n",
    "        random_state=0,\n",
    "        class_weight='balanced', \n",
    "        verbose=-1\n",
    "    )\n",
    "    categorical_features_indices = [X_train.columns.get_loc(c) for c in categorical_columns if c in X_train]\n",
    "    model.fit(X_train, y_train, categorical_feature=categorical_features_indices)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1_metric = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    imputed_values = model.predict(df_with_missing.drop(columns=[column_to_impute, 'jumlah_promosi']))\n",
    "    df.loc[df_with_missing.index, column_to_impute] = imputed_values\n",
    "\n",
    "    return df, f1_metric\n",
    "\n",
    "categorical_columns = ['status_pernikahan', 'pendidikan', 'keluhan']\n",
    "imputation_results = {}\n",
    "for column in categorical_columns:\n",
    "    if column in df.columns:\n",
    "        df, f1_metric = impute_categorical_data_with_lightgbm(df, column, categorical_columns)\n",
    "        imputation_results[column] = f1_metric\n",
    "    else:\n",
    "        imputation_results[column] = None\n",
    "\n",
    "print(imputation_results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'status_pernikahan': 0.41326530753954477, 'pendidikan': 0.6350493451558283, 'keluhan': 0.7493084370677732}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputasi Numerik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def impute_numerical_data_with_lightgbm(df, column_to_impute, categorical_columns):\n",
    "    if 'jumlah_promosi' in df.columns:\n",
    "        jumlah_promosi = df['jumlah_promosi'].copy()\n",
    "        df = df.drop(columns=['jumlah_promosi'])\n",
    "    else:\n",
    "        jumlah_promosi = None\n",
    "    \n",
    "    df_with_missing = df[df[column_to_impute].isna()].copy()\n",
    "    df_without_missing = df[~df[column_to_impute].isna()].copy()\n",
    "\n",
    "    X = df_without_missing.drop(columns=[column_to_impute])\n",
    "    y = df_without_missing[column_to_impute]\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype('category')\n",
    "        if col in df_with_missing.columns:\n",
    "            df_with_missing.loc[:, col] = df_with_missing[col].astype('category')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=31,\n",
    "        random_state=0\n",
    "    )\n",
    "    model.fit(X_train, y_train, categorical_feature=[col for col in categorical_columns if col in X.columns])\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    imputed_values = model.predict(df_with_missing.drop(columns=[column_to_impute]))\n",
    "    df.loc[df_with_missing.index, column_to_impute] = np.round(imputed_values).astype(int)\n",
    "\n",
    "    if jumlah_promosi is not None:\n",
    "        df['jumlah_promosi'] = jumlah_promosi\n",
    "\n",
    "    return df, mae\n",
    "\n",
    "\n",
    "categorical_columns = ['status_pernikahan', 'pendidikan', 'keluhan']\n",
    "\n",
    "integer_columns = [\n",
    "    'pendapatan', 'jumlah_anak_balita', 'jumlah_anak_remaja', 'terakhir_belanja', 'belanja_buah', 'belanja_daging', \n",
    "    'belanja_ikan', 'belanja_kue', 'pembelian_diskon', 'pembelian_web', 'pembelian_toko', \n",
    "    'umur', 'keanggotaan'\n",
    "]\n",
    "\n",
    "imputation_results = {}\n",
    "for column in integer_columns:\n",
    "    if column in df.columns:\n",
    "        df, mae = impute_numerical_data_with_lightgbm(df, column, categorical_columns)\n",
    "        imputation_results[column] = mae\n",
    "    else:\n",
    "        print(f\"The column '{column}' was not found in the DataFrame.\")\n",
    "        imputation_results[column] = None\n",
    "\n",
    "print(imputation_results)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memastikan data tidak negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "columns_to_correct = ['belanja_kue', 'belanja_daging', 'belanja_ikan', 'belanja_buah']\n",
    "\n",
    "for column in columns_to_correct:\n",
    "    df[column] = df[column].apply(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# print(df['keluhan'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "drop = ['keanggotaan']\n",
    "df = df.drop(drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "drop = ['keluhan']\n",
    "df = df.drop(drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre pro tahap 2 (Generate New Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daftar Variabel Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# # Variabel Pembantu\n",
    "df['jumlah_pembelian'] = df['pembelian_diskon'] + df['pembelian_web'] + df['pembelian_toko']\n",
    "df['total_belanja'] = df['belanja_daging'] + df['belanja_ikan'] + df['belanja_buah'] + df['belanja_kue']\n",
    "df[\"jumlah_anak\"] = df['jumlah_anak_balita'] + df['jumlah_anak_remaja']\n",
    "\n",
    "# 8018\n",
    "df['winsorized_pendapatan'] = winsorize(df['pendapatan'], limits=[0.01, 0.01])\n",
    "# 8038\n",
    "df['log_pendapatan'] = np.log(df['pendapatan'] + 1)\n",
    "# 8097\n",
    "df['ranked_pendapatan'] = df['pendapatan'].rank(method='average')\n",
    "# 8101\n",
    "df['cbrt_pendapatan'] = np.cbrt(df['pendapatan'])\n",
    "# 8108\n",
    "df['rasio_pembelian_diskon'] = df['pembelian_diskon']/(df['jumlah_pembelian']+1)\n",
    "# 8115\n",
    "df['proporsi_kue'] = df['belanja_kue'] / (df['belanja_buah'] + df['belanja_daging'] + df['belanja_ikan'] + df['belanja_kue'] + 1)\n",
    "# 8165\n",
    "df['pendapatan_kelompok_umur'] = df['winsorized_pendapatan'] / df['umur']\n",
    "# 8161\n",
    "df['log_shopping_frequency'] = np.log(df['total_belanja']+1)\n",
    "# 8140\n",
    "df['proporsi_buah'] = df['belanja_buah'] / (df['belanja_buah'] + df['belanja_daging'] + df['belanja_ikan'] + df['belanja_kue'] + 1)\n",
    "# 8181\n",
    "df['rasio_belanja_ikan'] = df['belanja_ikan'] / df['pendapatan']\n",
    "# 8181\n",
    "df['rasio_belanja_kue'] = df['belanja_kue'] / df['pendapatan']\n",
    "# 8212\n",
    "df['total_pembelian_toko_web_pendapatan'] = (df['pembelian_toko'] + df['pembelian_web']) / (df['pendapatan'] + 1)\n",
    "# 8199\n",
    "df['pendapatan_adjusted_umur_pendidikan'] = df['pendapatan'] / (df['umur'] * (df['pendidikan'].astype(int) + 1))\n",
    "# 8205\n",
    "df['rasio_pembelian_toko'] = df['pembelian_toko']/(df['jumlah_pembelian']+1)\n",
    "# 8214\n",
    "df['income_stability_score'] = df['pendapatan'] / (df[['belanja_buah', 'belanja_daging', 'belanja_ikan', 'belanja_kue']].std(axis=1) + 1)\n",
    "# 8204\n",
    "mean_income = np.log(df['pendapatan'].mean() + 1)\n",
    "df['log_pendapatan_vs_mean'] = np.log(df['pendapatan'] + 1) - mean_income\n",
    "# 8232\n",
    "df['log_age'] = np.log((df['umur']))\n",
    "\n",
    "\n",
    "# # 8212. 8184\n",
    "# df['budget_belanja_kue_perhari'] = (df['total_belanja'] - df['belanja_kue']) / (df['terakhir_belanja'] + 1) \n",
    "# 8157\n",
    "# df['high_value_customer'] = ((df['winsorized_pendapatan'] > df['winsorized_pendapatan'].quantile(0.75)) & (df['terakhir_belanja'] < df['terakhir_belanja'].quantile(0.25))).astype(int)\n",
    "# 8102. 8133\n",
    "# df['log_spending_ratio_kue'] = np.log(df['belanja_kue'] / (df['pendapatan'] + 1) + 1)\n",
    "\n",
    "# 8106\n",
    "# df['log_spending_ratio_ikan'] = np.log(df['belanja_ikan'] / (df['pendapatan'] + 1) + 1)\n",
    "# 8156\n",
    "# df['log_spending_ratio_buah'] = np.log(df['belanja_buah'] / (df['pendapatan'] + 1) + 1)\n",
    "# 8159\n",
    "# df['recency_frequency_score'] = (df['terakhir_belanja'] + 1) * df['pembelian_diskon']\n",
    "\n",
    "# # 8127\n",
    "# df['rasio_belanja_daging'] = df['belanja_daging'] / df['pendapatan']\n",
    "# 8105\n",
    "# df['pendapatan_per_jumlah_anak'] = df['pendapatan'] / (df['jumlah_anak'] + 1)\n",
    "# 8130\n",
    "# df['interaksi_pendidikan_pendapatan'] = (df['pendidikan'].astype(int) + 1) * df['winsorized_pendapatan']\n",
    "# 8180\n",
    "# df['rasio_belanja_buah'] = df['belanja_buah'] / df['winsorized_pendapatan'] \n",
    "# 8170\n",
    "# df['pendapatan_terhadap_buah_kue'] = df['winsorized_pendapatan'] / (df['belanja_buah'] + df['belanja_kue'] + 1)\n",
    "# 8075. 8135\n",
    "# df['total_belanja_protein'] = df['belanja_daging'] + df['belanja_ikan'] + df['belanja_buah'] \n",
    "# buah=8170, daging=8127\n",
    "# df['rasio_belanja_buah'] = df['belanja_daging'] / df['pendapatan']\n",
    "# 8126\n",
    "# df['rasio_pembelian_web'] = df['pembelian_web']/(df['jumlah_pembelian']+1)\n",
    "# 8141\n",
    "# df['log_dependency_ratio'] = np.log(df['pendapatan'] / (df['jumlah_anak_balita'] + df['jumlah_anak_remaja'] + 1) + 1)\n",
    "# 8148\n",
    "# df['log_spending_ratio_daging'] = np.log(df['belanja_daging'] / (df['winsorized_pendapatan'] + 1) + 1)\n",
    "# 8193\n",
    "# df['log_terakhir_belanja'] = np.log(df['terakhir_belanja'] + 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "drop = ['jumlah_pembelian', 'total_belanja', 'jumlah_anak']\n",
    "df = df.drop(drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"DataTrain10.csv\", index=False)\n",
    "# df.to_excel(\"DataTrain6.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('D:/Kuliah/NonAkademik/FindIT 2024/DataTrain10.csv')\n",
    "\n",
    "if 'jumlah_promosi' not in df.columns:\n",
    "    raise ValueError(\"The target variable 'jumlah_promosi' is not in the DataFrame.\")\n",
    "\n",
    "X = df.drop(columns=['jumlah_promosi'])\n",
    "y = df['jumlah_promosi']\n",
    "\n",
    "model = ExtraTreesClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=0,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    class_weight='balanced'  \n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    score = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_scores.append(score)\n",
    "\n",
    "average_f1_score = np.mean(f1_scores)\n",
    "print(f\"Average macro F1 Score: {average_f1_score:.4f}\")\n",
    "\n",
    "perm_importance = permutation_importance(model, X, y, n_repeats=10, random_state=0)\n",
    "\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(perm_importance.importances[sorted_idx].T, vert=False, labels=X.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('D:/Kuliah/NonAkademik/FindIT 2024/DataTrain10.csv')\n",
    "\n",
    "if 'jumlah_promosi' not in df.columns:\n",
    "    raise ValueError(\"The target variable 'jumlah_promosi' is not in the DataFrame.\")\n",
    "\n",
    "X = df.drop(columns=['jumlah_promosi'])\n",
    "y = df['jumlah_promosi']\n",
    "\n",
    "model = ExtraTreesClassifier(\n",
    "    n_estimators=393,\n",
    "    max_depth= 42,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='log2',\n",
    "    random_state=0,\n",
    "    criterion='gini',\n",
    "    class_weight='balanced'  \n",
    ")\n",
    "# {'n_estimators': 399, 'max_depth': 91, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
    "# {'n_estimators': 393, 'max_depth': 42, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    score = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_scores.append(score)\n",
    "\n",
    "average_f1_score = np.mean(f1_scores)\n",
    "print(f\"Average macro F1 Score: {average_f1_score:.4f}\")\n",
    "\n",
    "# perm_importance = permutation_importance(model, X, y, n_repeats=10, random_state=0)\n",
    "\n",
    "# sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.boxplot(perm_importance.importances[sorted_idx].T, vert=False, labels=X.columns[sorted_idx])\n",
    "# ax.set_title(\"Permutation Importances\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import optuna\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import f1_score, make_scorer\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# df = pd.read_csv('D:/Kuliah/NonAkademik/FindIT 2024/DataTrain10.csv')\n",
    "\n",
    "# if 'jumlah_promosi' not in df.columns:\n",
    "#     raise ValueError(\"The target variable 'jumlah_promosi' is not in the DataFrame.\")\n",
    "\n",
    "# X = df.drop(columns=['jumlah_promosi'])\n",
    "# y = df['jumlah_promosi']\n",
    "\n",
    "# def objective(trial):\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "#     max_depth = trial.suggest_int('max_depth', 5, 50)\n",
    "#     min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "#     min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "#     max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    \n",
    "#     model = ExtraTreesClassifier(\n",
    "#         n_estimators=n_estimators,\n",
    "#         max_depth=max_depth,\n",
    "#         min_samples_split=min_samples_split,\n",
    "#         min_samples_leaf=min_samples_leaf,\n",
    "#         max_features=max_features,\n",
    "#         random_state=0,\n",
    "#         criterion='gini',\n",
    "#         class_weight='balanced'  \n",
    "#     )\n",
    "\n",
    "#     kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "#     f1_scores = []\n",
    "\n",
    "#     for train_index, test_index in kfold.split(X, y):\n",
    "#         X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#         smote = SMOTE(random_state=0)\n",
    "#         X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#         model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "#         y_pred = model.predict(X_test)\n",
    "\n",
    "#         score = f1_score(y_test, y_pred, average='macro')\n",
    "#         f1_scores.append(score)\n",
    "\n",
    "#     average_f1_score = np.mean(f1_scores)\n",
    "#     return average_f1_score\n",
    "\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=200)\n",
    "\n",
    "# print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# best_model = ExtraTreesClassifier(\n",
    "#     n_estimators=study.best_params['n_estimators'],\n",
    "#     max_depth=study.best_params['max_depth'],\n",
    "#     min_samples_split=study.best_params['min_samples_split'],\n",
    "#     min_samples_leaf=study.best_params['min_samples_leaf'],\n",
    "#     max_features=study.best_params['max_features'],\n",
    "#     random_state=0,\n",
    "#     criterion='gini',\n",
    "#     class_weight='balanced'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"Scikit-Learn version:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "df = pd.read_csv('D:/Kuliah/NonAkademik/FindIT 2024/DataTrain10.csv')\n",
    "\n",
    "if 'jumlah_promosi' not in df.columns:\n",
    "    raise ValueError(\"The target variable 'jumlah_promosi' is not in the DataFrame.\")\n",
    "\n",
    "X = df.drop(columns=['jumlah_promosi'])\n",
    "y = df['jumlah_promosi']\n",
    "\n",
    "# model = ExtraTreesClassifier(\n",
    "#     n_estimators=100,\n",
    "#     random_state=0,\n",
    "#     criterion='gini',  \n",
    "#     max_depth=None,  \n",
    "#     class_weight='balanced'  \n",
    "# )\n",
    "\n",
    "model = ExtraTreesClassifier(\n",
    "    n_estimators=393,\n",
    "    max_depth= 42,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='log2',\n",
    "    random_state=0,\n",
    "    criterion='gini',\n",
    "    class_weight='balanced'  # To handle class imbalance\n",
    ")\n",
    "# # {'n_estimators': 393, 'max_depth': 42, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "model.fit(X_smote, y_smote)\n",
    "\n",
    "with gzip.open('model.pkl.gz', 'wb') as f:\n",
    "  pickle.dump(model, f)\n",
    "\n",
    "test_df = pd.read_csv(r\"D:/Kuliah/NonAkademik/FindIT 2024/DataTest.csv\")\n",
    "submission_df = pd.read_csv(r\"D:/Kuliah/NonAkademik/FindIT 2024/dataset/Submission.csv\")\n",
    "\n",
    "X_test = test_df  \n",
    "\n",
    "predictions = model.predict(X_test).astype(int)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'ID': submission_df['ID'],  \n",
    "    'jumlah_promosi': predictions\n",
    "})\n",
    "\n",
    "print(predictions)\n",
    "result_df.to_csv(r\"D:/Kuliah/NonAkademik/FindIT 2024/predictions10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# Load model yang telah dilatih\n",
    "with open('D:/Kuliah/NonAkademik/FindIT 2024/model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "data = {\n",
    "    'tahun_kelahiran': [1968],\n",
    "    'pendidikan': ['SMA'],\n",
    "    'status_pernikahan': ['Menikah'],\n",
    "    'pendapatan': [29857000],\n",
    "    'jumlah_anak_balita': [0],\n",
    "    'jumlah_anak_remaja': [0],\n",
    "    'terakhir_belanja': [34],\n",
    "    'belanja_buah': [8092.0],\n",
    "    'belanja_daging': [22253.0],\n",
    "    'belanja_ikan': [30345.0],\n",
    "    'belanja_kue': [26299],\n",
    "    'pembelian_diskon': [2],\n",
    "    'pembelian_web': [0],\n",
    "    'pembelian_toko': [5],\n",
    "    'keluhan': [0],\n",
    "    'tanggal_menjadi_anggota': ['2013-08-06']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df['umur'] = 2015 - df['tahun_kelahiran']\n",
    "df = df.drop(\"tahun_kelahiran\", axis=1)\n",
    "# print(df[\"umur\"].value_counts())\n",
    "\n",
    "Q1 = df['umur'].quantile(0.25)\n",
    "Q3 = df['umur'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 2 * IQR\n",
    "upper_bound = Q3 + 2 * IQR\n",
    "\n",
    "outliers = df[(df['umur'] < lower_bound) | (df['umur'] > upper_bound)]\n",
    "\n",
    "df.loc[(df['umur'] < lower_bound) | (df['umur'] > upper_bound), 'umur'] = np.nan\n",
    "\n",
    "\n",
    "df['tanggal_menjadi_anggota'] = pd.to_datetime(df['tanggal_menjadi_anggota'], errors='coerce')\n",
    "\n",
    "current_date = pd.to_datetime('2014-07-01')\n",
    "\n",
    "df['keanggotaan'] = ((current_date.year - df['tanggal_menjadi_anggota'].dt.year) * 12 +\n",
    "                            (current_date.month - df['tanggal_menjadi_anggota'].dt.month))\n",
    "\n",
    "df = df.drop(\"tanggal_menjadi_anggota\", axis=1)\n",
    "df['pendidikan'] = df['pendidikan'].replace({'Magister': 'Pasca_Sarjana', 'Doktor': 'Pasca_Sarjana'})\n",
    "\n",
    "education_order = {\n",
    "    'SMP': 0, 'SMA': 1, 'Sarjana': 2, 'Pasca Sarjana': 3\n",
    "}\n",
    "\n",
    "status_order = {\n",
    "    'Sendiri': 0, 'Rencana Menikah': 1, 'Menikah': 2, 'Cerai': 3, 'Cerai Mati': 4\n",
    "}\n",
    "df['pendidikan'] = df['pendidikan'].map(education_order)\n",
    "df['status_pernikahan'] = df['status_pernikahan'].map(status_order)\n",
    "columns_to_correct = ['belanja_kue', 'belanja_daging', 'belanja_ikan', 'belanja_buah']\n",
    "\n",
    "for column in columns_to_correct:\n",
    "    df[column] = df[column].apply(lambda x: max(x, 0))\n",
    "drop = ['keanggotaan']\n",
    "df = df.drop(drop, axis=1)\n",
    "drop = ['keluhan']\n",
    "df = df.drop(drop, axis=1)\n",
    "df['jumlah_pembelian'] = df['pembelian_diskon'] + df['pembelian_web'] + df['pembelian_toko']\n",
    "df['total_belanja'] = df['belanja_daging'] + df['belanja_ikan'] + df['belanja_buah'] + df['belanja_kue']\n",
    "df[\"jumlah_anak\"] = df['jumlah_anak_balita'] + df['jumlah_anak_remaja']\n",
    "\n",
    "# 8018\n",
    "df['winsorized_pendapatan'] = winsorize(df['pendapatan'], limits=[0.01, 0.01])\n",
    "# 8038\n",
    "df['log_pendapatan'] = np.log(df['pendapatan'] + 1)\n",
    "# 8097\n",
    "df['ranked_pendapatan'] = df['pendapatan'].rank(method='average')\n",
    "# 8101\n",
    "df['cbrt_pendapatan'] = np.cbrt(df['pendapatan'])\n",
    "# 8108\n",
    "df['rasio_pembelian_diskon'] = df['pembelian_diskon']/(df['jumlah_pembelian']+1)\n",
    "# 8115\n",
    "df['proporsi_kue'] = df['belanja_kue'] / (df['belanja_buah'] + df['belanja_daging'] + df['belanja_ikan'] + df['belanja_kue'] + 1)\n",
    "# 8165\n",
    "df['pendapatan_kelompok_umur'] = df['winsorized_pendapatan'] / df['umur']\n",
    "# 8161\n",
    "df['log_shopping_frequency'] = np.log(df['total_belanja']+1)\n",
    "# 8140\n",
    "df['proporsi_buah'] = df['belanja_buah'] / (df['belanja_buah'] + df['belanja_daging'] + df['belanja_ikan'] + df['belanja_kue'] + 1)\n",
    "# 8181\n",
    "df['rasio_belanja_ikan'] = df['belanja_ikan'] / df['pendapatan']\n",
    "# 8181\n",
    "df['rasio_belanja_kue'] = df['belanja_kue'] / df['pendapatan']\n",
    "# 8212\n",
    "df['total_pembelian_toko_web_pendapatan'] = (df['pembelian_toko'] + df['pembelian_web']) / (df['pendapatan'] + 1)\n",
    "# 8199\n",
    "df['pendapatan_adjusted_umur_pendidikan'] = df['pendapatan'] / (df['umur'] * (df['pendidikan'].astype(int) + 1))\n",
    "# 8205\n",
    "df['rasio_pembelian_toko'] = df['pembelian_toko']/(df['jumlah_pembelian']+1)\n",
    "# 8214\n",
    "df['income_stability_score'] = df['pendapatan'] / (df[['belanja_buah', 'belanja_daging', 'belanja_ikan', 'belanja_kue']].std(axis=1) + 1)\n",
    "# 8204\n",
    "mean_income = np.log(df['pendapatan'].mean() + 1)\n",
    "df['log_pendapatan_vs_mean'] = np.log(df['pendapatan'] + 1) - mean_income\n",
    "# 8232\n",
    "df['log_age'] = np.log((df['umur']))\n",
    "drop = ['jumlah_pembelian', 'total_belanja', 'jumlah_anak']\n",
    "df = df.drop(drop, axis=1)\n",
    "# df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Melakukan prediksi menggunakan model yang sudah dilatih\n",
    "prediksi = model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print('Hasil Prediksi:', prediksi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
